{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092e8e52-7615-4cd2-8a68-c6d0f961165b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from ch4 import GPTModel\n",
    "\n",
    "GPT_CONGIG_124M = {\n",
    "        \"vocab_size\":     50257,  # Vocabulary size\n",
    "        \"context_length\": 256,    # Context length\n",
    "        \"emb_dim\":        768,    # Embedding dimension\n",
    "        \"n_heads\":        12,     # Number of attention heads\n",
    "        \"n_layers\":       12,     # Number of layers\n",
    "        \"drop_rate\":      0.1,    # Dropout rate\n",
    "        \"qkv_bias\":       False   # Query-Key-Value bias\n",
    "    }\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONGIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22296dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from ch4 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Adds the batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    flat = token_ids.squeeze(0)   # Removes the batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(start_context,tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONGIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4cf33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      " every effort moves \n",
      " I really like\n",
      "targets:\n",
      "  effort moves you \n",
      "  really like chocolate\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([\n",
    "    [16833,3626,6100],\n",
    "    [40,1107,588]\n",
    "])\n",
    "targets = torch.tensor([\n",
    "    [3626,6100,345],\n",
    "    [1107,588,11311]\n",
    "])\n",
    "print(\"inputs:\\n\",token_ids_to_text(inputs[0].unsqueeze(0),tokenizer),\"\\n\",token_ids_to_text(inputs[1].unsqueeze(0),tokenizer))\n",
    "print(\"targets:\\n\",token_ids_to_text(targets[0].unsqueeze(0),tokenizer),\"\\n\",token_ids_to_text(targets[1].unsqueeze(0),tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345344df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1: effort moves you\n",
      "Outputs batch 1: Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)                  # 1.求出logits\n",
    "probas = torch.softmax(logits,dim=-1)       # 2.求出所有Probabilities\n",
    "print(probas.shape)\n",
    "token_ids = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "print(\"Token IDs:\\n\",token_ids)\n",
    "print(f\"Targets batch 1:{token_ids_to_text(targets[0],tokenizer)}\")\n",
    "print(f\"Outputs batch 1:{token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a491fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n",
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx,[0,1,2],targets[text_idx]]   # 3.求出目标的probability\n",
    "print(\"Text 1:\",target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx,[0,1,2],targets[text_idx]]   # 3.求出目标的probability\n",
    "print(\"Text 2:\",target_probas_2)\n",
    "\n",
    "log_probas = torch.log(torch.cat((target_probas_1,target_probas_2)))   # 4.求出log的probability\n",
    "print(log_probas)\n",
    "\n",
    "avg_log_probas = torch.mean(log_probas)    # 5.求出平均的probability\n",
    "print(avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = -avg_log_probas      # 6.求负的，结果是一个entrop loss\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c404d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits shape: torch.Size([6, 50257])\n",
      "Flattened targets shape: torch.Size([6])\n",
      "Flattened logits:\n",
      " tensor([[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
      "        [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
      "        [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217],\n",
      "        [-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
      "        [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
      "        [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]])\n",
      "Flattened targets:\n",
      " tensor([ 3626,  6100,   345,  1107,   588, 11311])\n",
      "Entropy loss: tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\",logits.shape)\n",
    "print(\"Targets shape:\",targets.shape)\n",
    "\n",
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits shape:\",logits_flat.shape)\n",
    "print(\"Flattened targets shape:\",targets_flat.shape)\n",
    "print(\"Flattened logits:\\n\",logits_flat)\n",
    "print(\"Flattened targets:\\n\",targets_flat)\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(\"Entropy loss:\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c047ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path,\"r\",encoding='utf-8') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\",total_characters)\n",
    "print(\"Tokens:\",total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8dd008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liuhz\\Desktop\\files\\projects\\LLM\\Chapter5\\ch2.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.input_ids[idx]),torch.tensor(self.target_ids[idx])\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "from ch2 import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONGIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONGIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONGIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONGIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79eab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1),target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646e3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader,model,device,num_batchs=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batchs is None:\n",
    "        num_batchs = len(data_loader)\n",
    "    else:\n",
    "        num_batchs = min(num_batchs,len(data_loader))\n",
    "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
    "        if i<num_batchs:\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3e29d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758316040039\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device)\n",
    "print(\"Training loss:\",train_loss)\n",
    "print(\"Validation loss:\",val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2250d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader,model,device,num_batchs=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device,num_batchs=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ace2561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model,tokenizer,device,start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx = encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids,tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\",\" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28ea89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model,train_loader,val_loader,\n",
    "                       optimizer,device,num_epochs,\n",
    "                       eval_freq,eval_iter,start_context,tokenizer):\n",
    "    train_losses,val_losses,track_tokens_seen = [],[],[]\n",
    "    tokens_seen,global_step = 0,-1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch,target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss,val_loss = evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        \n",
    "        generate_and_print_sample(\n",
    "            model,tokenizer,device,start_context\n",
    "        )\n",
    "    \n",
    "    return train_losses,val_losses,track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f4f3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liuhz\\Desktop\\files\\projects\\LLM\\Chapter5\\ch2.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.input_ids[idx]),torch.tensor(self.target_ids[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.823, Val loss 9.932\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.336\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.621, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.043, Val loss 6.599\n",
      "Every effort moves you, and,, and,, and,,,, and, and,,,,,,,,, and,,,, the,,,, and,, and,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.547, Val loss 6.485\n",
      "Ep 3 (Step 000025): Train loss 5.450, Val loss 6.397\n",
      "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had, and, and, and, and, and, and, and, and, and,\n",
      "Ep 4 (Step 000030): Train loss 4.982, Val loss 6.301\n",
      "Ep 4 (Step 000035): Train loss 4.755, Val loss 6.296\n",
      "Every effort moves you, and I had been the of the picture to the picture.                                     \n",
      "Ep 5 (Step 000040): Train loss 4.162, Val loss 6.182\n",
      "Every effort moves you know the                                                \n",
      "Ep 6 (Step 000045): Train loss 3.742, Val loss 6.175\n",
      "Ep 6 (Step 000050): Train loss 3.213, Val loss 6.189\n",
      "Every effort moves you know the fact, and I felt--I had the fact a little of a little to my work, and in fact, and in the picture.      \"--and it, and, and down, and he was his\n",
      "Ep 7 (Step 000055): Train loss 3.143, Val loss 6.172\n",
      "Ep 7 (Step 000060): Train loss 2.422, Val loss 6.136\n",
      "Every effort moves you know the picture.  I glanced after him, and I was one of the house.\"   \"I didn't you know. I was his pictures.  \"--and I was a little a little the room, I was\n",
      "Ep 8 (Step 000065): Train loss 1.963, Val loss 6.178\n",
      "Ep 8 (Step 000070): Train loss 1.639, Val loss 6.230\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"Once, when I looked up, I had been. Gisburn--as Jack himself, as once one had been the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.286, Val loss 6.227\n",
      "Ep 9 (Step 000080): Train loss 0.987, Val loss 6.249\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs. \"--and I was a year after Jack's resolve had been his eyes; then I looked at the donkey--and I saw that, and down the room, I had\n",
      "Ep 10 (Step 000085): Train loss 0.727, Val loss 6.356\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONGIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.0004,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses,val_losses,tokens_seen = train_model_simple(\n",
    "    model,train_loader,val_loader,optimizer,device,\n",
    "    num_epochs=num_epochs,eval_freq=5,eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eacc096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen,tokens_seen,train_losses,val_losses):\n",
    "    fig,ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen,train_losses,label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen,val_losses,linestyle=\"-.\",label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen,train_losses,alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
    "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05429c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONGIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9218df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,idx,max_new_tokens,context_size,temperature=0.0,top_k=None,eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits,_ = torch.topk(logits,top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx,idx_next),dim=1)\n",
    "    \n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad62f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to happen. It was not it was such not to see her\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model = model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONGIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df03ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "torch.save({\n",
    "    \"model_state_dict\":model.state_dict(),\n",
    "    \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a55899c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuhz\\AppData\\Local\\Temp\\ipykernel_4576\\3979599727.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_and_optimizer.pth\",map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\",map_location=device)\n",
    "model = GPTModel(GPT_CONGIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=5e-4,weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553c45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
